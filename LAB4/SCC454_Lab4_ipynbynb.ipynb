{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPO2hhNSb0KiNxKB1G+NSt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NateMophi/SCC-454/blob/main/LAB4/SCC454_Lab4_ipynbynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSsvJ7MWFlJh",
        "outputId": "281300a4-49a0-4fe2-bd6b-6aceaafb9883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install pyspark==3.5.0 -q\n",
        "!pip install sentence-transformers -q\n",
        "!pip install numpy pandas -q\n",
        "\n",
        "# Install Java (Spark requires Java)\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Set Java environment variable\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "\n",
        "print(\"All packages installed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIY_GNL1Fr6R",
        "outputId": "93d676a3-3d69-424a-9d62-23bd1f00756b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All packages installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import hashlib\n",
        "from typing import List, Set, Tuple"
      ],
      "metadata": {
        "id": "SpNBUmiWHS8r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import(\n",
        "    col, udf, explode, array, lit, collect_list, size, lower, regexp_replace, split, monotonically_increasing_id, struct,\n",
        "    when, coalesce, broadcast\n",
        ")\n",
        "\n",
        "from pyspark.sql.types import(\n",
        "    ArrayType, StringType, IntegerType, FloatType, StructType, StructField,\n",
        "    DoubleType\n",
        ")\n",
        "\n",
        "from pyspark.ml.feature import (\n",
        "    HashingTF, CountVectorizer, MinHashLSH,\n",
        "    Tokenizer, StopWordsRemover, NGram\n",
        ")\n",
        "\n",
        "from pyspark.ml.linalg import Vectors, SparseVector, VectorUDT\n",
        "from pyspark.ml import Pipeline\n",
        "\n"
      ],
      "metadata": {
        "id": "mARe4OcvGT1-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spark Session for LSH Operations\n",
        "spark = SparkSession.builder.appName(\"SCC454-LocalitySensitiveHashing\")\\\n",
        ".config(\"spark.driver.memory\", \"4g\")\\\n",
        ".config(\"spark.sql.shuffle.partitions\", \"8\")\\\n",
        ".config(\"spark.ui.port\", \"4050\")\\\n",
        ".getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "print(f\"Spark Version: {spark.version}\")\n",
        "print(f\"App Name: {spark.sparkContext.appName}\")\n",
        "print(\"\\nSpark Session Ready for LSH ops!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VDkHZRkGTzw",
        "outputId": "722a0da1-9dbb-4953-923a-5497071035e4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark Version: 3.5.0\n",
            "App Name: SCC454-LocalitySensitiveHashing\n",
            "\n",
            "Spark Session Ready for LSH ops!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SAMPLE DATASET"
      ],
      "metadata": {
        "id": "gjZRYGfyK5Fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample document corpus with varying degrees of similarity\n",
        "documents = [\n",
        "    (0, \"Machine learning is a subset of artificial intelligence that enables systems to learn from data.\"),\n",
        "    (1, \"Artificial intelligence and machine learning allow computers to learn from data automatically.\"),\n",
        "    (2, \"Deep learning is a type of machine learning using neural networks with many layers.\"),\n",
        "    (3, \"The weather today is sunny with a high of 25 degrees celsius.\"),\n",
        "    (4, \"Today's weather forecast shows sunny skies and temperatures around 25 degrees.\"),\n",
        "    (5, \"Natural language processing helps computers understand human language.\"),\n",
        "    (6, \"NLP enables machines to process and understand natural human language.\"),\n",
        "    (7, \"Python is a popular programming language for data science and machine learning.\"),\n",
        "    (8, \"Data science often uses Python programming for machine learning applications.\"),\n",
        "    (9, \"The cat sat on the mat and watched the birds outside the window.\"),\n",
        "    (10, \"A small cat was sitting on a mat, watching birds through the window.\"),\n",
        "    (11, \"Apache Spark provides distributed computing for big data processing.\"),\n",
        "    (12, \"Big data processing is made efficient through distributed computing with Spark.\"),\n",
        "    (13, \"Locality sensitive hashing enables fast approximate nearest neighbor search.\"),\n",
        "    (14, \"LSH provides fast approximate nearest neighbor queries using hashing techniques.\"),\n",
        "    (15, \"The restaurant serves delicious Italian pasta and fresh salads daily.\"),\n",
        "]\n",
        "\n",
        "df_docs = spark.createDataFrame(documents, [\"id\", \"text\"])\n",
        "\n",
        "print(\"Sample Document Corpus:\")\n",
        "df_docs.show(truncate=60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rofcOP7KGTxS",
        "outputId": "87fc280e-f003-4855-f978-ce04f1907a03"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Document Corpus:\n",
            "+---+------------------------------------------------------------+\n",
            "| id|                                                        text|\n",
            "+---+------------------------------------------------------------+\n",
            "|  0|Machine learning is a subset of artificial intelligence t...|\n",
            "|  1|Artificial intelligence and machine learning allow comput...|\n",
            "|  2|Deep learning is a type of machine learning using neural ...|\n",
            "|  3|The weather today is sunny with a high of 25 degrees cels...|\n",
            "|  4|Today's weather forecast shows sunny skies and temperatur...|\n",
            "|  5|Natural language processing helps computers understand hu...|\n",
            "|  6|NLP enables machines to process and understand natural hu...|\n",
            "|  7|Python is a popular programming language for data science...|\n",
            "|  8|Data science often uses Python programming for machine le...|\n",
            "|  9|The cat sat on the mat and watched the birds outside the ...|\n",
            "| 10|A small cat was sitting on a mat, watching birds through ...|\n",
            "| 11|Apache Spark provides distributed computing for big data ...|\n",
            "| 12|Big data processing is made efficient through distributed...|\n",
            "| 13|Locality sensitive hashing enables fast approximate neare...|\n",
            "| 14|LSH provides fast approximate nearest neighbor queries us...|\n",
            "| 15|The restaurant serves delicious Italian pasta and fresh s...|\n",
            "+---+------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DOCUMENT SHINGLING**"
      ],
      "metadata": {
        "id": "l679jTqOLdGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Part 2: Document Shingling\n",
        "---\n",
        "\n",
        "## 2.1 Understanding Shingling\n",
        "\n",
        "**What is Shingling?**\n",
        "Shingling converts documents into sets of contiguous subsequences (shingles). This allows us to measure document similarity by comparing these sets.\n",
        "\n",
        "**Types of Shingles:**\n",
        "\n",
        "| Type | Description | Example (\"hello world\") |\n",
        "|------|-------------|-------------------------|\n",
        "| Character k-shingles | Contiguous k characters | {\"hel\", \"ell\", \"llo\", \"lo \", \"o w\", ...} |\n",
        "| Word n-grams | Contiguous n words | {\"hello world\"} for n=2 |\n",
        "\n",
        "**Choosing Shingle Size:**\n",
        "- Too small: High overlap even for dissimilar documents\n",
        "- Too large: Low overlap even for similar documents\n",
        "- Rule of thumb: k=5-9 for characters, n=2-4 for words"
      ],
      "metadata": {
        "id": "fHJQ7zqQMlkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHARACTER SHINGLES\n",
        "def get_char_shingles(text:str, k:int =5):\n",
        "  \"\"\"Generate character k-shingles from text\"\"\"\n",
        "  text = \" \".join(text.lower().split())\n",
        "\n",
        "  # Generate Shingles\n",
        "  shingles = [text[i:i+k] for i in range(len(text) - k + 1)]\n",
        "  return shingles\n",
        "\n",
        "# Example\n",
        "sample_text = \"Hello World\"\n",
        "char_shingles = get_char_shingles(sample_text, k=5)\n",
        "print(f\"Text: '{sample_text}'\")\n",
        "print(f\"5-character shingles: {char_shingles}\")\n",
        "print(f\"Number of shingles: {len(char_shingles)}\")\n",
        "print(f\"Unique shingles: {len(set(char_shingles))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nki2oPJGTqs",
        "outputId": "2be6f1b7-283a-4550-cbd0-8d785c813acc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 'Hello World'\n",
            "5-character shingles: ['hello', 'ello ', 'llo w', 'lo wo', 'o wor', ' worl', 'world']\n",
            "Number of shingles: 7\n",
            "Unique shingles: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WORD SHINGLES\n",
        "def get_word_shingles(text: str, n:int=3)-> List[str]:\n",
        "  words = text.lower().split()\n",
        "  shingles = [\" \".join(words[i:i+n]) for i in range(len(words) - n + 1)]\n",
        "  return shingles\n",
        "\n",
        "  # Example\n",
        "sample_text = \"Machine learning is a subset of artificial intelligence\"\n",
        "word_shingles = get_word_shingles(sample_text, n=3)\n",
        "print(f\"Text: '{sample_text}'\")\n",
        "print(f\"\\n3-word shingles:\")\n",
        "for i, shingle in enumerate(word_shingles):\n",
        "    print(f\"  {i+1}. '{shingle}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSYw0I6zGToB",
        "outputId": "b39c1699-95a2-4a02-9f9b-24ad0db03618"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 'Machine learning is a subset of artificial intelligence'\n",
            "\n",
            "3-word shingles:\n",
            "  1. 'machine learning is'\n",
            "  2. 'learning is a'\n",
            "  3. 'is a subset'\n",
            "  4. 'a subset of'\n",
            "  5. 'subset of artificial'\n",
            "  6. 'of artificial intelligence'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dj8npgsOGTlZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}