{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NateMophi/SCC-454/blob/main/LAB2/SCC454_Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvaH_Aif9u-V",
        "outputId": "36fa428f-c2b9-4809-9a3c-0c9c82471ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dldqkvaN_Ajn"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark==4.0.0 -q\n",
        "\n",
        "# Java Installation\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rZYa7FCMAQNo"
      },
      "outputs": [],
      "source": [
        "# Set Java environmenr variable\n",
        "import os\n",
        "os.environ[\"JAVA HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "\n",
        "print(\"PySpark & Java installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qMwjYI6qAyUN"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkConf\n",
        "\n",
        "# Session Creation\n",
        "spark = SparkSession.builder.appName(\"SCC454-SparkIntro\").config(\"spark.driver.memory\", \"4g\")\\\n",
        "        .config(\"spark.ui.port\", \"4050\")\\\n",
        "        .getOrCreate()\n",
        "\n",
        "  # Underlying Context\n",
        "sc = spark.sparkContext\n",
        "print(f\"Spark Version: {spark.version}\")\n",
        "print(f\"Spark App Name: {spark.sparkContext.appName}\")\n",
        "print(f\"Master: {spark.sparkContext.master}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdzhTGEgG7Ac"
      },
      "source": [
        "# **Resilient Distributed Datasets (RDDs)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrujuHElHEAd"
      },
      "outputs": [],
      "source": [
        "# RDD Creation\n",
        "\n",
        "# 1a) Parallelization from a Python Collection\n",
        "nums = [1,2,3,4,5,6,7,8,9,10]\n",
        "nums_rdd =sc.parallelize(nums)\n",
        "\n",
        "type(nums_rdd)\n",
        "print(f\"Number of paritions: {nums_rdd.getNumPartitions()}\")\n",
        "print(f\"First 5 elements : {nums_rdd.take(5)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCrISMJPHD5x"
      },
      "outputs": [],
      "source": [
        "# 1b) Parallelize with a specific number of partitions\n",
        "nums_rdd_4part = sc.parallelize(nums, 4)\n",
        "print(f\"Number of partitions: {nums_rdd_4part.getNumPartitions()}\")\n",
        "\n",
        "# View Partitions\n",
        "print(\"\\nData in each partition: \")\n",
        "print(nums_rdd_4part.glom().collect())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anms-b20HFVc"
      },
      "outputs": [],
      "source": [
        "# 2) Create RDD from text file\n",
        "sample_text = \"\"\"Apache Spark is a unified analytics engine for large-scale data processing.\n",
        "It provides high-level APIs in Java, Scala, Python and R.\n",
        "Spark powers a stack of libraries including SQL and DataFrames.\n",
        "It also includes MLlib for machine learning and GraphX for graph processing.\n",
        "Spark can run on Hadoop, Apache Mesos, Kubernetes, standalone, or in the cloud.\"\"\"\n",
        "\n",
        "\n",
        "with open(\"spark_intro.txt\", \"w\") as f:\n",
        "  f.write(sample_text)\n",
        "\n",
        "# Load text file as RDD\n",
        "text_rdd = sc.textFile(\"spark_intro.txt\")\n",
        "print(f\"Number of lines: {text_rdd.count()}\")\n",
        "print(\"\\n1st 3 lines:\")\n",
        "for line in text_rdd.take(3):\n",
        "  print(f\" - {line}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n"
      ],
      "metadata": {
        "id": "R-i7lEaVkTob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"naught\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3TV9lfZn_nM",
        "outputId": "000275bf-e849-48a9-9c68-7467a38554e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "\n",
            "Initial commit\n",
            "\n",
            "nothing to commit (create/copy files and use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push"
      ],
      "metadata": {
        "id": "4vg42SvNoKxv",
        "outputId": "be4add29-cbc7-40ae-9851-b5ce97fcd3d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error: src refspec refs/heads/main does not match any\n",
            "\u001b[31merror: failed to push some refs to 'https://github.com/NateMophi/SCC-454.git'\n",
            "\u001b[m"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}